package cmd

import (
	"fmt"
	"os"
	"path/filepath"
	"strings"

	"github.com/spf13/cobra"
)

var initCmd = &cobra.Command{
	Use:   "init <name>",
	Short: "Scaffold a new Agent-Forge project",
	Long: `Creates a new agent project directory with the required boilerplate:
  - data/          Empty directory for your PDF/Markdown source files
  - agent.yaml     Persona, models, and interface configuration
  - Dockerfile     Pre-configured for building Docker image
  - .env.example   Template for runtime environment variables
  - .dockerignore  Excludes raw data files from the final image`,
	Args: cobra.ExactArgs(1),
	RunE: runInit,
}

func runInit(cmd *cobra.Command, args []string) error {
	name := args[0]
	projectDir := filepath.Join(".", name)

	// Check if directory already exists
	if _, err := os.Stat(projectDir); err == nil {
		return fmt.Errorf("directory %q already exists", name)
	}

	fmt.Printf("Initializing new agent project: %s\n", name)

	// Create directory structure
	dirs := []string{
		projectDir,
		filepath.Join(projectDir, "data"),
	}
	for _, dir := range dirs {
		if err := os.MkdirAll(dir, 0755); err != nil {
			return fmt.Errorf("create directory %q: %w", dir, err)
		}
	}

	// Write agent.yaml
	agentYAML := generateAgentYAML(name)
	if err := writeFile(filepath.Join(projectDir, "agent.yaml"), agentYAML); err != nil {
		return fmt.Errorf("write agent.yaml: %w", err)
	}

	// Write Dockerfile
	if err := writeFile(filepath.Join(projectDir, "Dockerfile"), generateDockerfile()); err != nil {
		return fmt.Errorf("write Dockerfile: %w", err)
	}

	// Write .env.example
	if err := writeFile(filepath.Join(projectDir, ".env.example"), generateEnvExample()); err != nil {
		return fmt.Errorf("write .env.example: %w", err)
	}

	// Write .dockerignore
	if err := writeFile(filepath.Join(projectDir, ".dockerignore"), generateDockerIgnore()); err != nil {
		return fmt.Errorf("write .dockerignore: %w", err)
	}

	// Write README
	if err := writeFile(filepath.Join(projectDir, "README.md"), generateReadme(name)); err != nil {
		return fmt.Errorf("write README.md: %w", err)
	}

	fmt.Printf("\nProject created successfully!\n\n")
	fmt.Printf("Next steps:\n")
	fmt.Printf("  1. cd %s\n", name)
	fmt.Printf("  2. Add documents to the data/ directory\n")
	fmt.Printf("  3. Edit agent.yaml to configure your agent's persona\n")
	fmt.Printf("  4. Run: agentforge build\n")
	fmt.Printf("  5. Run: docker build -t %s:latest .\n", name)

	return nil
}

func writeFile(path, content string) error {
	return os.WriteFile(path, []byte(content), 0644)
}

func generateAgentYAML(name string) string {
	slug := strings.ToLower(strings.ReplaceAll(name, " ", "-"))
	return fmt.Sprintf(`# Agent-Forge Configuration
# Generated by: agentforge init %s

agent:
  name: "%s"
  version: "1.0.0"
  description: "An expert AI agent powered by Agent-Forge"

  # System prompt injected at runtime for all interfaces
  system_prompt: |
    You are %s, a highly knowledgeable expert assistant.
    You have access to a specialized knowledge base compiled from expert documents.
    Always ground your responses in the retrieved context.
    Be precise, helpful, and cite your knowledge when possible.

# Runtime model preferences (overridden by env vars)
runtime:
  llm:
    model: "gpt-4o"
  embedder:
    model: "voyage-3"

# MCP tool definitions (auto-populated by 'agentforge build')
mcp:
  tools:
    - name: "search_%s_knowledge"
      description: "Search the expert knowledge base for relevant information. Use this tool when the user asks about topics covered in the agent's domain."
      # NOTE: This description will be auto-optimized by 'agentforge build'

# Server configuration
server:
  port: 8000
  cors_origins:
    - "*"
`, name, name, name, slug)
}

func generateDockerfile() string {
	return `# Agent-Forge Runtime Dockerfile
# Packages compiled databases with the agentforge binary (~50MB)
#
# Uses the multi-arch base image (amd64 + arm64) published to GHCR.
# At runtime it executes "agentforge serve" which starts the HTTP server
# exposing REST, MCP, and A2A interfaces on port 8000.
#
# Build for current architecture:
#   docker build -t my-agent:latest .
#
# Build multi-arch and push (share with the world):
#   docker buildx build --platform linux/amd64,linux/arm64 -t my-registry/my-agent:v1 --push .

FROM ghcr.io/agent-forge/agentforge:latest

WORKDIR /app

# Copy the compiled database artifacts from 'agentforge build'
COPY data/memory.chromem/ /app/data/memory.chromem/
COPY data/knowledge.cayley/ /app/data/knowledge.cayley/

# Copy the agent configuration
COPY agent.yaml /app/agent.yaml

# Runtime API keys injected via environment variables (BYOM)
# Required:
ENV LLM_BASE_URL=""
ENV LLM_API_KEY=""
ENV LLM_MODEL=""
ENV EMBED_BASE_URL=""
ENV EMBED_API_KEY=""
ENV EMBED_MODEL=""
# Optional reranker:
ENV RERANK_BASE_URL=""
ENV RERANK_API_KEY=""
ENV RERANK_MODEL=""

EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=3s --start-period=5s \
  CMD wget -qO- http://localhost:8000/health || exit 1

ENTRYPOINT ["/app/agentforge", "serve"]
`
}

func generateEnvExample() string {
	return `# Agent-Forge Runtime Environment Variables
# Copy this to .env and fill in your values
# Then: docker run --env-file .env my-agent:latest

# LLM Provider (required) - must be OpenAI-compatible
LLM_BASE_URL=https://api.openai.com/v1
LLM_API_KEY=sk-your-key-here
LLM_MODEL=gpt-4o

# Embedding Provider (required) - must be OpenAI-compatible
EMBED_BASE_URL=https://api.voyageai.com/v1
EMBED_API_KEY=pa-your-key-here
EMBED_MODEL=voyage-3

# Reranking Provider (optional) - must be OpenAI-compatible
# RERANK_BASE_URL=
# RERANK_API_KEY=
# RERANK_MODEL=
`
}

func generateDockerIgnore() string {
	return `# Exclude raw source files from Docker image
# The compiled databases (memory.chromem/, knowledge.cayley/) are what matters

# Raw data sources
data/*.pdf
data/*.md
data/*.txt
data/*.docx

# Development artifacts
*.log
*.tmp
.env
.env.local

# Go build artifacts (if any)
bin/
`
}

func generateReadme(name string) string {
	return fmt.Sprintf(`# %s - Agent-Forge Project

An expert AI agent built with [Agent-Forge](https://github.com/agent-forge/agent-forge).

## Quick Start

### Prerequisites
- [Agent-Forge CLI](https://github.com/agent-forge/agent-forge) installed
- OpenAI-compatible LLM and embedding API access
- Docker (with buildx for multi-arch)

### Build

1. Add your knowledge documents to the `+"`data/`"+` directory:
   `+"```"+`bash
   cp my-document.pdf data/
   cp my-notes.md data/
   `+"```"+`

2. Configure your build providers in `+"`~/.agent-forge/config.yaml`"+`

3. Compile the knowledge base:
   `+"```"+`bash
   agentforge build
   `+"```"+`

4. Build the Docker image (current architecture):
   `+"```"+`bash
   docker build -t %s:latest .
   `+"```"+`

5. Or build multi-arch and push (share with the world):
   `+"```"+`bash
   docker buildx build --platform linux/amd64,linux/arm64 -t my-registry/%s:v1 --push .
   `+"```"+`

### Run

`+"```"+`bash
docker run -p 8000:8000 \
  -e LLM_BASE_URL="https://api.openai.com/v1" \
  -e LLM_API_KEY="sk-..." \
  -e LLM_MODEL="gpt-4o" \
  -e EMBED_BASE_URL="https://api.voyageai.com/v1" \
  -e EMBED_API_KEY="pa-..." \
  -e EMBED_MODEL="voyage-3" \
  -e RERANK_BASE_URL=""   `+"`# optional`"+` \
  -e RERANK_API_KEY=""    `+"`# optional`"+` \
  -e RERANK_MODEL=""      `+"`# optional`"+` \
  %s:latest
`+"```"+`

## Interfaces

- **REST API**: `+"`POST http://localhost:8000/v1/chat/completions`"+` (OpenAI-compatible)
- **MCP Server**: `+"`GET http://localhost:8000/mcp`"+` (for Cursor, Windsurf)
- **A2A Protocol**: `+"`POST http://localhost:8000/rpc/agent`"+` (for AutoGen, CrewAI)
`, name, name, name, name)
}
